"""
Dog vs Cat Classification - Streamlit App
==========================================
á»¨ng dá»¥ng demo model ConvMixer cho bÃ i toÃ¡n phÃ¢n loáº¡i ChÃ³/MÃ¨o.

TÃ¡i hiá»‡n tá»« paper: "Patches Are All You Need?" (ConvMixer)
"""

import streamlit as st
import torch
import numpy as np
import json
import io
from PIL import Image
import matplotlib.pyplot as plt
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
from pytorch_grad_cam.utils.model_targets import BinaryClassifierOutputTarget

# Import tá»« model_utils
from model_utils import (
    load_model_from_hub,
    predict,
    preprocess_image,
    get_transform,
    get_target_layer,
    REPO_ID,
    CLASS_NAMES
)

# ============================================================================
# Cáº¤U HÃŒNH TRANG
# ============================================================================
st.set_page_config(
    page_title="ğŸ±ğŸ¶ Dog vs Cat Classifier",
    page_icon="ğŸ¾",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# CUSTOM CSS
# ============================================================================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        background: linear-gradient(90deg, #FF6B6B, #4ECDC4);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1rem;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .prediction-box {
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
        margin: 1rem 0;
    }
    .dog-prediction {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    .cat-prediction {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        text-align: center;
        border-left: 4px solid #4ECDC4;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
    }
    .stTabs [data-baseweb="tab"] {
        font-size: 1.1rem;
        font-weight: 600;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# CACHE MODEL - Load model má»™t láº§n vÃ  cache
# ============================================================================
@st.cache_resource
def load_cached_model():
    """Load model tá»« HF Hub vÃ  cache Ä‘á»ƒ khÃ´ng pháº£i load láº¡i."""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = load_model_from_hub(device=device)
    return model, device


# ============================================================================
# GRAD-CAM FUNCTION
# ============================================================================
def generate_gradcam(model, image: Image.Image, device: str):
    """
    Táº¡o Grad-CAM heatmap Ä‘á»ƒ giáº£i thÃ­ch model Ä‘ang nhÃ¬n vÃ o Ä‘Ã¢u.
    
    Args:
        model: Model Ä‘Ã£ load
        image: PIL Image gá»‘c
        device: Device cá»§a model
    
    Returns:
        visualization: áº¢nh vá»›i heatmap overlay
    """
    # Láº¥y target layer
    target_layer = get_target_layer(model)
    
    # Khá»Ÿi táº¡o GradCAM
    cam = GradCAM(model=model, target_layers=[target_layer])
    
    # Tiá»n xá»­ lÃ½ áº£nh cho model
    transform = get_transform()
    input_tensor = preprocess_image(image, transform)
    input_tensor = input_tensor.to(device)
    
    # Dá»± Ä‘oÃ¡n trÆ°á»›c Ä‘á»ƒ biáº¿t class nÃ o Ä‘Æ°á»£c predict
    with torch.no_grad():
        output = model(input_tensor)
        prob = torch.sigmoid(output).item()
    
    # Binary classification: output > 0.5 -> Dog (category=1), else Cat (category=0)
    # BinaryClassifierOutputTarget sáº½ Ä‘áº£o dáº¥u gradient náº¿u category=0 (Cat)
    # Äiá»u nÃ y Ä‘áº£m báº£o Grad-CAM highlight Ä‘Ãºng vÃ¹ng cho cáº£ Dog vÃ  Cat
    predicted_category = 1 if prob >= 0.5 else 0
    targets = [BinaryClassifierOutputTarget(predicted_category)]
    
    # Táº¡o grayscale cam vá»›i target phÃ¹ há»£p
    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)
    grayscale_cam = grayscale_cam[0, :]  # Láº¥y batch Ä‘áº§u tiÃªn
    
    # Chuáº©n bá»‹ áº£nh gá»‘c (resize vá» 224x224 vÃ  normalize vá» [0,1])
    image_resized = image.resize((224, 224))
    rgb_img = np.array(image_resized) / 255.0
    
    # Overlay heatmap lÃªn áº£nh
    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)
    
    return visualization


# ============================================================================
# TAB 1: DEMO
# ============================================================================
def render_demo_tab():
    """Render ná»™i dung tab Demo."""
    
    st.markdown("### ğŸ“¸ Upload áº£nh Ä‘á»ƒ phÃ¢n loáº¡i")
    st.markdown("Há»— trá»£ Ä‘á»‹nh dáº¡ng: JPG, JPEG, PNG")
    
    # Upload áº£nh
    uploaded_file = st.file_uploader(
        "Chá»n áº£nh...",
        type=["jpg", "jpeg", "png"],
        help="Upload áº£nh chÃ³ hoáº·c mÃ¨o Ä‘á»ƒ model dá»± Ä‘oÃ¡n"
    )
    
    if uploaded_file is not None:
        # Äá»c áº£nh
        image = Image.open(uploaded_file)
        
        # Load model (cached)
        with st.spinner("ğŸ”„ Äang táº£i model..."):
            try:
                model, device = load_cached_model()
            except Exception as e:
                st.error(f"""
                âŒ **Lá»—i khi táº£i model!**
                
                Vui lÃ²ng kiá»ƒm tra:
                1. ÄÃ£ cáº­p nháº­t `REPO_ID` trong file `model_utils.py` chÆ°a?
                2. Repository trÃªn Hugging Face Hub Ä‘Ã£ public chÆ°a?
                3. File `model.pt` Ä‘Ã£ Ä‘Æ°á»£c upload lÃªn repository chÆ°a?
                
                Chi tiáº¿t lá»—i: {str(e)}
                """)
                return
        
        # Layout 2 cá»™t
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ–¼ï¸ áº¢nh gá»‘c")
            st.image(image, use_column_width=True)
        
        with col2:
            st.markdown("#### ğŸ”¥ Grad-CAM Heatmap")
            with st.spinner("Äang táº¡o Grad-CAM..."):
                try:
                    gradcam_img = generate_gradcam(model, image, device)
                    st.image(gradcam_img, width=224) 
                    st.caption("VÃ¹ng mÃ u Ä‘á»/vÃ ng = nÆ¡i model táº­p trung Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh")
                except Exception as e:
                    st.warning(f"KhÃ´ng thá»ƒ táº¡o Grad-CAM: {str(e)}")
        
        # Dá»± Ä‘oÃ¡n
        st.markdown("---")
        st.markdown("### ğŸ¯ Káº¿t quáº£ dá»± Ä‘oÃ¡n")
        
        with st.spinner("Äang phÃ¢n tÃ­ch..."):
            result = predict(model, image, device)
        
        # Hiá»ƒn thá»‹ káº¿t quáº£
        predicted_class = result["class"]
        confidence = result["confidence"]
        probs = result["probabilities"]
        
        # Chá»n style dá»±a trÃªn káº¿t quáº£
        if predicted_class == "Dog":
            emoji = "ğŸ¶"
            style_class = "dog-prediction"
        else:
            emoji = "ğŸ±"
            style_class = "cat-prediction"
        
        # Hiá»ƒn thá»‹ prediction box
        st.markdown(f"""
        <div class="prediction-box {style_class}">
            <h1>{emoji} {predicted_class}</h1>
            <h3>Äá»™ tin cáº­y: {confidence:.2f}%</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Progress bars cho xÃ¡c suáº¥t
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("ğŸ± **Cat**")
            st.progress(probs["Cat"] / 100)
            st.markdown(f"**{probs['Cat']:.2f}%**")
        
        with col2:
            st.markdown("ğŸ¶ **Dog**")
            st.progress(probs["Dog"] / 100)
            st.markdown(f"**{probs['Dog']:.2f}%**")
    
    else:
        # Placeholder khi chÆ°a upload
        st.info("ğŸ‘† Vui lÃ²ng upload áº£nh chÃ³ hoáº·c mÃ¨o Ä‘á»ƒ báº¯t Ä‘áº§u!")
        
        # Sample images info
        with st.expander("ğŸ’¡ Gá»£i Ã½"):
            st.markdown("""
            - áº¢nh nÃªn rÃµ rÃ ng, cÃ³ chá»§ thá»ƒ lÃ  chÃ³ hoáº·c mÃ¨o
            - Model hoáº¡t Ä‘á»™ng tá»‘t nháº¥t vá»›i áº£nh cÃ³ ná»n Ä‘Æ¡n giáº£n
            - Há»— trá»£ cÃ¡c Ä‘á»‹nh dáº¡ng phá»• biáº¿n: JPG, PNG
            """)


# ============================================================================
# TAB 2: REPORT
# ============================================================================
def render_report_tab():
    """Render ná»™i dung tab Report."""
    
    st.markdown("### ğŸ“Š BÃ¡o cÃ¡o káº¿t quáº£ huáº¥n luyá»‡n")
    st.markdown("So sÃ¡nh hiá»‡u suáº¥t giá»¯a **ResNet34** vÃ  **ConvMixer** trÃªn dataset Dog vs Cat")
    
    # Load results
    try:
        with open("results.json", "r") as f:
            results = json.load(f)
    except FileNotFoundError:
        st.error("âŒ KhÃ´ng tÃ¬m tháº¥y file `results.json`!")
        return
    except json.JSONDecodeError:
        st.error("âŒ File `results.json` khÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng!")
        return
    
    # Láº¥y data
    resnet_data = results.get("result_resnet", {})
    convmixer_data = results.get("result_convmixer", {})
    
    # ===== METRICS OVERVIEW =====
    st.markdown("#### ğŸ† Tá»•ng quan hiá»‡u suáº¥t")
    
    col1, col2, col3, col4 = st.columns(4)
    
    # Best validation accuracy
    resnet_best_acc = max(resnet_data.get("valid_metric", [0])) * 100
    convmixer_best_acc = max(convmixer_data.get("valid_metric", [0])) * 100
    
    # Final validation loss
    resnet_final_loss = resnet_data.get("valid_loss", [0])[-1]
    convmixer_final_loss = convmixer_data.get("valid_loss", [0])[-1]
    
    with col1:
        st.metric(
            label="ğŸ¯ ResNet34 - Best Acc",
            value=f"{resnet_best_acc:.2f}%",
            delta=None
        )
    
    with col2:
        st.metric(
            label="ğŸ¯ ConvMixer - Best Acc",
            value=f"{convmixer_best_acc:.2f}%",
            delta=f"+{convmixer_best_acc - resnet_best_acc:.2f}%" if convmixer_best_acc > resnet_best_acc else f"{convmixer_best_acc - resnet_best_acc:.2f}%"
        )
    
    with col3:
        st.metric(
            label="ğŸ“‰ ResNet34 - Final Loss",
            value=f"{resnet_final_loss:.4f}"
        )
    
    with col4:
        st.metric(
            label="ğŸ“‰ ConvMixer - Final Loss",
            value=f"{convmixer_final_loss:.4f}",
            delta=f"{convmixer_final_loss - resnet_final_loss:.4f}" if convmixer_final_loss < resnet_final_loss else f"+{convmixer_final_loss - resnet_final_loss:.4f}",
            delta_color="inverse"
        )
    
    st.markdown("---")
    
    # ===== BIá»‚U Äá»’ =====
    st.markdown("#### ğŸ“ˆ Biá»ƒu Ä‘á»“ quÃ¡ trÃ¬nh huáº¥n luyá»‡n")
    
    # Chuáº©n bá»‹ data
    epochs = list(range(1, len(resnet_data.get("train_loss", [])) + 1))
    
    # Colors
    resnet_color = '#FF6B6B'
    convmixer_color = '#4ECDC4'
    train_style = '-'
    valid_style = '--'
    
    # Helper function to create download buttons for a chart
    def add_download_buttons(fig, chart_name, key_suffix):
        # Save to PDF
        pdf_buffer = io.BytesIO()
        fig.savefig(pdf_buffer, format='pdf', bbox_inches='tight', dpi=300)
        pdf_buffer.seek(0)
        
        # Save to SVG
        svg_buffer = io.BytesIO()
        fig.savefig(svg_buffer, format='svg', bbox_inches='tight')
        svg_buffer.seek(0)
        
        # 2 nÃºt náº±m ngang cáº¡nh nhau
        btn_col1, btn_col2 = st.columns(2)
        with btn_col1:
            st.download_button(
                label="ğŸ“¥ PDF",
                data=pdf_buffer,
                file_name=f"{chart_name}.pdf",
                mime="application/pdf",
                key=f"download_{key_suffix}_pdf"
            )
        with btn_col2:
            st.download_button(
                label="ğŸ“¥ SVG",
                data=svg_buffer,
                file_name=f"{chart_name}.svg",
                mime="image/svg+xml",
                key=f"download_{key_suffix}_svg"
            )
        
        plt.close(fig)
    
    # Layout 2 cá»™t cho cÃ¡c biá»ƒu Ä‘á»“
    col_chart1, col_chart2 = st.columns(2)
    
    # 1. Training Loss
    with col_chart1:
        fig1, ax1 = plt.subplots(figsize=(7, 5))
        ax1.plot(epochs, resnet_data.get("train_loss", []), train_style, 
                 color=resnet_color, label='ResNet34', linewidth=2)
        ax1.plot(epochs, convmixer_data.get("train_loss", []), train_style, 
                 color=convmixer_color, label='ConvMixer', linewidth=2)
        ax1.set_title("Training Loss", fontsize=12, fontweight='bold')
        ax1.set_xlabel("Epoch")
        ax1.set_ylabel("Loss")
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig1)
        add_download_buttons(fig1, "training_loss", "train_loss")
    
    # 2. Validation Loss
    with col_chart2:
        fig2, ax2 = plt.subplots(figsize=(7, 5))
        ax2.plot(epochs, resnet_data.get("valid_loss", []), valid_style, 
                 color=resnet_color, label='ResNet34', linewidth=2, marker='o')
        ax2.plot(epochs, convmixer_data.get("valid_loss", []), valid_style, 
                 color=convmixer_color, label='ConvMixer', linewidth=2, marker='s')
        ax2.set_title("Validation Loss", fontsize=12, fontweight='bold')
        ax2.set_xlabel("Epoch")
        ax2.set_ylabel("Loss")
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig2)
        add_download_buttons(fig2, "validation_loss", "valid_loss")
    
    # Layout 2 cá»™t tiáº¿p theo
    col_chart3, col_chart4 = st.columns(2)
    
    # 3. Training Accuracy
    with col_chart3:
        fig3, ax3 = plt.subplots(figsize=(7, 5))
        train_acc_resnet = [x * 100 for x in resnet_data.get("train_metric", [])]
        train_acc_convmixer = [x * 100 for x in convmixer_data.get("train_metric", [])]
        ax3.plot(epochs, train_acc_resnet, train_style, 
                 color=resnet_color, label='ResNet34', linewidth=2)
        ax3.plot(epochs, train_acc_convmixer, train_style, 
                 color=convmixer_color, label='ConvMixer', linewidth=2)
        ax3.set_title("Training Accuracy", fontsize=12, fontweight='bold')
        ax3.set_xlabel("Epoch")
        ax3.set_ylabel("Accuracy (%)")
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        ax3.set_ylim([70, 100])
        plt.tight_layout()
        st.pyplot(fig3)
        add_download_buttons(fig3, "training_accuracy", "train_acc")
    
    # 4. Validation Accuracy
    with col_chart4:
        fig4, ax4 = plt.subplots(figsize=(7, 5))
        valid_acc_resnet = [x * 100 for x in resnet_data.get("valid_metric", [])]
        valid_acc_convmixer = [x * 100 for x in convmixer_data.get("valid_metric", [])]
        ax4.plot(epochs, valid_acc_resnet, valid_style, 
                 color=resnet_color, label='ResNet34', linewidth=2, marker='o')
        ax4.plot(epochs, valid_acc_convmixer, valid_style, 
                 color=convmixer_color, label='ConvMixer', linewidth=2, marker='s')
        ax4.set_title("Validation Accuracy", fontsize=12, fontweight='bold')
        ax4.set_xlabel("Epoch")
        ax4.set_ylabel("Accuracy (%)")
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        ax4.set_ylim([90, 100])
        plt.tight_layout()
        st.pyplot(fig4)
        add_download_buttons(fig4, "validation_accuracy", "valid_acc")
    
    st.markdown("---")
    
    # ===== Báº¢NG CHI TIáº¾T =====
    st.markdown("#### ğŸ“‹ Báº£ng sá»‘ liá»‡u chi tiáº¿t")
    
    tab_resnet, tab_convmixer = st.tabs(["ğŸ“Š ResNet34", "ğŸ“Š ConvMixer"])
    
    with tab_resnet:
        import pandas as pd
        df_resnet = pd.DataFrame({
            "Epoch": epochs,
            "Train Loss": [f"{x:.4f}" for x in resnet_data.get("train_loss", [])],
            "Valid Loss": [f"{x:.4f}" for x in resnet_data.get("valid_loss", [])],
            "Train Acc (%)": [f"{x*100:.2f}" for x in resnet_data.get("train_metric", [])],
            "Valid Acc (%)": [f"{x*100:.2f}" for x in resnet_data.get("valid_metric", [])]
        })
        st.dataframe(df_resnet, use_container_width=True)
    
    with tab_convmixer:
        import pandas as pd
        df_convmixer = pd.DataFrame({
            "Epoch": epochs,
            "Train Loss": [f"{x:.4f}" for x in convmixer_data.get("train_loss", [])],
            "Valid Loss": [f"{x:.4f}" for x in convmixer_data.get("valid_loss", [])],
            "Train Acc (%)": [f"{x*100:.2f}" for x in convmixer_data.get("train_metric", [])],
            "Valid Acc (%)": [f"{x*100:.2f}" for x in convmixer_data.get("valid_metric", [])]
        })
        st.dataframe(df_convmixer, use_container_width=True)
    
    # ===== Káº¾T LUáº¬N =====
    st.markdown("---")
    st.markdown("#### ğŸ’¡ Káº¿t luáº­n")
    
    winner = "ConvMixer" if convmixer_best_acc >= resnet_best_acc else "ResNet34"
    
    st.success(f"""
    ğŸ† **{winner}** Ä‘áº¡t hiá»‡u suáº¥t tá»‘t nháº¥t trÃªn validation set!
    
    - **ResNet34**: {resnet_best_acc:.2f}% accuracy
    - **ConvMixer**: {convmixer_best_acc:.2f}% accuracy
    
    ConvMixer - má»™t kiáº¿n trÃºc Ä‘Æ¡n giáº£n chá»‰ dÃ¹ng patch embeddings vÃ  depthwise convolutions - 
    Ä‘Ã£ chá»©ng minh hiá»‡u quáº£ cáº¡nh tranh vá»›i ResNet trÃªn bÃ i toÃ¡n Dog vs Cat, 
    phÃ¹ há»£p vá»›i káº¿t luáº­n cá»§a paper "Patches Are All You Need?".
    """)


# ============================================================================
# SIDEBAR
# ============================================================================
def render_sidebar():
    """Render sidebar vá»›i thÃ´ng tin bá»• sung."""
    
    with st.sidebar:
        st.markdown("## ğŸ¾ Dog vs Cat Classifier")
        st.markdown("---")
        
        st.markdown("### ğŸ“– Vá» project")
        st.markdown("""
        ÄÃ¢y lÃ  á»©ng dá»¥ng demo model **ConvMixer** Ä‘Æ°á»£c huáº¥n luyá»‡n 
        trÃªn dataset Dog vs Cat.
        
        **Paper gá»‘c:** *"Patches Are All You Need?"*
        """)
        
        st.markdown("---")
        
        st.markdown("### ğŸ› ï¸ ThÃ´ng tin ká»¹ thuáº­t")
        st.markdown(f"""
        - **Model:** ConvMixer-768/32
        - **Input size:** 224x224
        - **Classes:** Cat, Dog
        - **Framework:** PyTorch + timm
        """)
        
        st.markdown("---")
        
        st.markdown("### ğŸ”— Links")
        st.markdown("""
        - [ConvMixer Paper](https://arxiv.org/abs/2201.09792)
        - [timm Library](https://github.com/huggingface/pytorch-image-models)
        """)
        
        st.markdown("---")
        
        # Device info
        device = "CUDA ğŸš€" if torch.cuda.is_available() else "CPU"
        st.info(f"**Device:** {device}")


# ============================================================================
# MAIN APP
# ============================================================================
def main():
    """HÃ m chÃ­nh cháº¡y á»©ng dá»¥ng."""
    
    # Render sidebar
    render_sidebar()
    
    # Header
    st.markdown('<h1 class="main-header">ğŸ± Dog vs Cat Classifier ğŸ¶</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Powered by ConvMixer - "Patches Are All You Need?"</p>', unsafe_allow_html=True)
    
    # Tabs
    tab1, tab2 = st.tabs(["ğŸ® Demo", "ğŸ“Š Report"])
    
    with tab1:
        render_demo_tab()
    
    with tab2:
        render_report_tab()
    
    # Footer
    st.markdown("---")
    st.markdown(
        "<p style='text-align: center; color: #888;'>Made with â¤ï¸ using Streamlit | Machine Learning Project</p>",
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
