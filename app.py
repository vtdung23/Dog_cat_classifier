"""
Dog vs Cat Classification - Streamlit App
==========================================
·ª®ng d·ª•ng demo model ConvMixer cho b√†i to√°n ph√¢n lo·∫°i Ch√≥/M√®o.

T√°i hi·ªán t·ª´ paper: "Patches Are All You Need?" (ConvMixer)
"""

import streamlit as st
import torch
import numpy as np
import json
from PIL import Image
import matplotlib.pyplot as plt
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image

# Import t·ª´ model_utils
from model_utils import (
    load_model_from_hub,
    predict,
    preprocess_image,
    get_transform,
    get_target_layer,
    REPO_ID,
    CLASS_NAMES
)

# ============================================================================
# C·∫§U H√åNH TRANG
# ============================================================================
st.set_page_config(
    page_title="üê±üê∂ Dog vs Cat Classifier",
    page_icon="üêæ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# CUSTOM CSS
# ============================================================================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        background: linear-gradient(90deg, #FF6B6B, #4ECDC4);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1rem;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .prediction-box {
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
        margin: 1rem 0;
    }
    .dog-prediction {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    .cat-prediction {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        text-align: center;
        border-left: 4px solid #4ECDC4;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
    }
    .stTabs [data-baseweb="tab"] {
        font-size: 1.1rem;
        font-weight: 600;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# CACHE MODEL - Load model m·ªôt l·∫ßn v√† cache
# ============================================================================
@st.cache_resource
def load_cached_model():
    """Load model t·ª´ HF Hub v√† cache ƒë·ªÉ kh√¥ng ph·∫£i load l·∫°i."""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = load_model_from_hub(device=device)
    return model, device


# ============================================================================
# GRAD-CAM FUNCTION
# ============================================================================
def generate_gradcam(model, image: Image.Image, device: str):
    """
    T·∫°o Grad-CAM heatmap ƒë·ªÉ gi·∫£i th√≠ch model ƒëang nh√¨n v√†o ƒë√¢u.
    
    Args:
        model: Model ƒë√£ load
        image: PIL Image g·ªëc
        device: Device c·ªßa model
    
    Returns:
        visualization: ·∫¢nh v·ªõi heatmap overlay
    """
    # L·∫•y target layer
    target_layer = get_target_layer(model)
    
    # Kh·ªüi t·∫°o GradCAM
    cam = GradCAM(model=model, target_layers=[target_layer])
    
    # Ti·ªÅn x·ª≠ l√Ω ·∫£nh cho model
    transform = get_transform()
    input_tensor = preprocess_image(image, transform)
    input_tensor = input_tensor.to(device)
    
    # T·∫°o grayscale cam
    grayscale_cam = cam(input_tensor=input_tensor, targets=None)
    grayscale_cam = grayscale_cam[0, :]  # L·∫•y batch ƒë·∫ßu ti√™n
    
    # Chu·∫©n b·ªã ·∫£nh g·ªëc (resize v·ªÅ 224x224 v√† normalize v·ªÅ [0,1])
    image_resized = image.resize((224, 224))
    rgb_img = np.array(image_resized) / 255.0
    
    # Overlay heatmap l√™n ·∫£nh
    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)
    
    return visualization


# ============================================================================
# TAB 1: DEMO
# ============================================================================
def render_demo_tab():
    """Render n·ªôi dung tab Demo."""
    
    st.markdown("### üì∏ Upload ·∫£nh ƒë·ªÉ ph√¢n lo·∫°i")
    st.markdown("H·ªó tr·ª£ ƒë·ªãnh d·∫°ng: JPG, JPEG, PNG")
    
    # Upload ·∫£nh
    uploaded_file = st.file_uploader(
        "Ch·ªçn ·∫£nh...",
        type=["jpg", "jpeg", "png"],
        help="Upload ·∫£nh ch√≥ ho·∫∑c m√®o ƒë·ªÉ model d·ª± ƒëo√°n"
    )
    
    if uploaded_file is not None:
        # ƒê·ªçc ·∫£nh
        image = Image.open(uploaded_file)
        
        # Load model (cached)
        with st.spinner("üîÑ ƒêang t·∫£i model..."):
            try:
                model, device = load_cached_model()
            except Exception as e:
                st.error(f"""
                ‚ùå **L·ªói khi t·∫£i model!**
                
                Vui l√≤ng ki·ªÉm tra:
                1. ƒê√£ c·∫≠p nh·∫≠t `REPO_ID` trong file `model_utils.py` ch∆∞a?
                2. Repository tr√™n Hugging Face Hub ƒë√£ public ch∆∞a?
                3. File `model.pt` ƒë√£ ƒë∆∞·ª£c upload l√™n repository ch∆∞a?
                
                Chi ti·∫øt l·ªói: {str(e)}
                """)
                return
        
        # Layout 2 c·ªôt
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üñºÔ∏è ·∫¢nh g·ªëc")
            st.image(image, use_container_width=True)
        
        with col2:
            st.markdown("#### üî• Grad-CAM Heatmap")
            with st.spinner("ƒêang t·∫°o Grad-CAM..."):
                try:
                    gradcam_img = generate_gradcam(model, image, device)
                    st.image(gradcam_img, use_container_width=True)
                    st.caption("V√πng m√†u ƒë·ªè/v√†ng = n∆°i model t·∫≠p trung ƒë·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh")
                except Exception as e:
                    st.warning(f"Kh√¥ng th·ªÉ t·∫°o Grad-CAM: {str(e)}")
        
        # D·ª± ƒëo√°n
        st.markdown("---")
        st.markdown("### üéØ K·∫øt qu·∫£ d·ª± ƒëo√°n")
        
        with st.spinner("ƒêang ph√¢n t√≠ch..."):
            result = predict(model, image, device)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        predicted_class = result["class"]
        confidence = result["confidence"]
        probs = result["probabilities"]
        
        # Ch·ªçn style d·ª±a tr√™n k·∫øt qu·∫£
        if predicted_class == "Dog":
            emoji = "üê∂"
            style_class = "dog-prediction"
        else:
            emoji = "üê±"
            style_class = "cat-prediction"
        
        # Hi·ªÉn th·ªã prediction box
        st.markdown(f"""
        <div class="prediction-box {style_class}">
            <h1>{emoji} {predicted_class}</h1>
            <h3>ƒê·ªô tin c·∫≠y: {confidence:.2f}%</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Progress bars cho x√°c su·∫•t
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("üê± **Cat**")
            st.progress(probs["Cat"] / 100)
            st.markdown(f"**{probs['Cat']:.2f}%**")
        
        with col2:
            st.markdown("üê∂ **Dog**")
            st.progress(probs["Dog"] / 100)
            st.markdown(f"**{probs['Dog']:.2f}%**")
    
    else:
        # Placeholder khi ch∆∞a upload
        st.info("üëÜ Vui l√≤ng upload ·∫£nh ch√≥ ho·∫∑c m√®o ƒë·ªÉ b·∫Øt ƒë·∫ßu!")
        
        # Sample images info
        with st.expander("üí° G·ª£i √Ω"):
            st.markdown("""
            - ·∫¢nh n√™n r√µ r√†ng, c√≥ ch·ªß th·ªÉ l√† ch√≥ ho·∫∑c m√®o
            - Model ho·∫°t ƒë·ªông t·ªët nh·∫•t v·ªõi ·∫£nh c√≥ n·ªÅn ƒë∆°n gi·∫£n
            - H·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng ph·ªï bi·∫øn: JPG, PNG
            """)


# ============================================================================
# TAB 2: REPORT
# ============================================================================
def render_report_tab():
    """Render n·ªôi dung tab Report."""
    
    st.markdown("### üìä B√°o c√°o k·∫øt qu·∫£ hu·∫•n luy·ªán")
    st.markdown("So s√°nh hi·ªáu su·∫•t gi·ªØa **ResNet34** v√† **ConvMixer** tr√™n dataset Dog vs Cat")
    
    # Load results
    try:
        with open("results.json", "r") as f:
            results = json.load(f)
    except FileNotFoundError:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y file `results.json`!")
        return
    except json.JSONDecodeError:
        st.error("‚ùå File `results.json` kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng!")
        return
    
    # L·∫•y data
    resnet_data = results.get("result_resnet", {})
    convmixer_data = results.get("result_convmixer", {})
    
    # ===== METRICS OVERVIEW =====
    st.markdown("#### üèÜ T·ªïng quan hi·ªáu su·∫•t")
    
    col1, col2, col3, col4 = st.columns(4)
    
    # Best validation accuracy
    resnet_best_acc = max(resnet_data.get("valid_metric", [0])) * 100
    convmixer_best_acc = max(convmixer_data.get("valid_metric", [0])) * 100
    
    # Final validation loss
    resnet_final_loss = resnet_data.get("valid_loss", [0])[-1]
    convmixer_final_loss = convmixer_data.get("valid_loss", [0])[-1]
    
    with col1:
        st.metric(
            label="üéØ ResNet34 - Best Acc",
            value=f"{resnet_best_acc:.2f}%",
            delta=None
        )
    
    with col2:
        st.metric(
            label="üéØ ConvMixer - Best Acc",
            value=f"{convmixer_best_acc:.2f}%",
            delta=f"+{convmixer_best_acc - resnet_best_acc:.2f}%" if convmixer_best_acc > resnet_best_acc else f"{convmixer_best_acc - resnet_best_acc:.2f}%"
        )
    
    with col3:
        st.metric(
            label="üìâ ResNet34 - Final Loss",
            value=f"{resnet_final_loss:.4f}"
        )
    
    with col4:
        st.metric(
            label="üìâ ConvMixer - Final Loss",
            value=f"{convmixer_final_loss:.4f}",
            delta=f"{convmixer_final_loss - resnet_final_loss:.4f}" if convmixer_final_loss < resnet_final_loss else f"+{convmixer_final_loss - resnet_final_loss:.4f}",
            delta_color="inverse"
        )
    
    st.markdown("---")
    
    # ===== BI·ªÇU ƒê·ªí =====
    st.markdown("#### üìà Bi·ªÉu ƒë·ªì qu√° tr√¨nh hu·∫•n luy·ªán")
    
    # Chu·∫©n b·ªã data
    epochs = list(range(1, len(resnet_data.get("train_loss", [])) + 1))
    
    # T·∫°o figure v·ªõi 2x2 subplots
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle("Training History Comparison", fontsize=16, fontweight='bold')
    
    # Colors
    resnet_color = '#FF6B6B'
    convmixer_color = '#4ECDC4'
    train_style = '-'
    valid_style = '--'
    
    # 1. Training Loss
    ax1 = axes[0, 0]
    ax1.plot(epochs, resnet_data.get("train_loss", []), train_style, 
             color=resnet_color, label='ResNet34 - Train', linewidth=2)
    ax1.plot(epochs, convmixer_data.get("train_loss", []), train_style, 
             color=convmixer_color, label='ConvMixer - Train', linewidth=2)
    ax1.set_title("Training Loss", fontsize=12, fontweight='bold')
    ax1.set_xlabel("Epoch")
    ax1.set_ylabel("Loss")
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. Validation Loss
    ax2 = axes[0, 1]
    ax2.plot(epochs, resnet_data.get("valid_loss", []), valid_style, 
             color=resnet_color, label='ResNet34 - Valid', linewidth=2, marker='o')
    ax2.plot(epochs, convmixer_data.get("valid_loss", []), valid_style, 
             color=convmixer_color, label='ConvMixer - Valid', linewidth=2, marker='s')
    ax2.set_title("Validation Loss", fontsize=12, fontweight='bold')
    ax2.set_xlabel("Epoch")
    ax2.set_ylabel("Loss")
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. Training Accuracy
    ax3 = axes[1, 0]
    train_acc_resnet = [x * 100 for x in resnet_data.get("train_metric", [])]
    train_acc_convmixer = [x * 100 for x in convmixer_data.get("train_metric", [])]
    ax3.plot(epochs, train_acc_resnet, train_style, 
             color=resnet_color, label='ResNet34 - Train', linewidth=2)
    ax3.plot(epochs, train_acc_convmixer, train_style, 
             color=convmixer_color, label='ConvMixer - Train', linewidth=2)
    ax3.set_title("Training Accuracy", fontsize=12, fontweight='bold')
    ax3.set_xlabel("Epoch")
    ax3.set_ylabel("Accuracy (%)")
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.set_ylim([70, 100])
    
    # 4. Validation Accuracy
    ax4 = axes[1, 1]
    valid_acc_resnet = [x * 100 for x in resnet_data.get("valid_metric", [])]
    valid_acc_convmixer = [x * 100 for x in convmixer_data.get("valid_metric", [])]
    ax4.plot(epochs, valid_acc_resnet, valid_style, 
             color=resnet_color, label='ResNet34 - Valid', linewidth=2, marker='o')
    ax4.plot(epochs, valid_acc_convmixer, valid_style, 
             color=convmixer_color, label='ConvMixer - Valid', linewidth=2, marker='s')
    ax4.set_title("Validation Accuracy", fontsize=12, fontweight='bold')
    ax4.set_xlabel("Epoch")
    ax4.set_ylabel("Accuracy (%)")
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.set_ylim([90, 100])
    
    plt.tight_layout()
    st.pyplot(fig)
    
    st.markdown("---")
    
    # ===== B·∫¢NG CHI TI·∫æT =====
    st.markdown("#### üìã B·∫£ng s·ªë li·ªáu chi ti·∫øt")
    
    tab_resnet, tab_convmixer = st.tabs(["üìä ResNet34", "üìä ConvMixer"])
    
    with tab_resnet:
        import pandas as pd
        df_resnet = pd.DataFrame({
            "Epoch": epochs,
            "Train Loss": [f"{x:.4f}" for x in resnet_data.get("train_loss", [])],
            "Valid Loss": [f"{x:.4f}" for x in resnet_data.get("valid_loss", [])],
            "Train Acc (%)": [f"{x*100:.2f}" for x in resnet_data.get("train_metric", [])],
            "Valid Acc (%)": [f"{x*100:.2f}" for x in resnet_data.get("valid_metric", [])]
        })
        st.dataframe(df_resnet, use_container_width=True, hide_index=True)
    
    with tab_convmixer:
        import pandas as pd
        df_convmixer = pd.DataFrame({
            "Epoch": epochs,
            "Train Loss": [f"{x:.4f}" for x in convmixer_data.get("train_loss", [])],
            "Valid Loss": [f"{x:.4f}" for x in convmixer_data.get("valid_loss", [])],
            "Train Acc (%)": [f"{x*100:.2f}" for x in convmixer_data.get("train_metric", [])],
            "Valid Acc (%)": [f"{x*100:.2f}" for x in convmixer_data.get("valid_metric", [])]
        })
        st.dataframe(df_convmixer, use_container_width=True, hide_index=True)
    
    # ===== K·∫æT LU·∫¨N =====
    st.markdown("---")
    st.markdown("#### üí° K·∫øt lu·∫≠n")
    
    winner = "ConvMixer" if convmixer_best_acc >= resnet_best_acc else "ResNet34"
    
    st.success(f"""
    üèÜ **{winner}** ƒë·∫°t hi·ªáu su·∫•t t·ªët nh·∫•t tr√™n validation set!
    
    - **ResNet34**: {resnet_best_acc:.2f}% accuracy
    - **ConvMixer**: {convmixer_best_acc:.2f}% accuracy
    
    ConvMixer - m·ªôt ki·∫øn tr√∫c ƒë∆°n gi·∫£n ch·ªâ d√πng patch embeddings v√† depthwise convolutions - 
    ƒë√£ ch·ª©ng minh hi·ªáu qu·∫£ c·∫°nh tranh v·ªõi ResNet tr√™n b√†i to√°n Dog vs Cat, 
    ph√π h·ª£p v·ªõi k·∫øt lu·∫≠n c·ªßa paper "Patches Are All You Need?".
    """)


# ============================================================================
# SIDEBAR
# ============================================================================
def render_sidebar():
    """Render sidebar v·ªõi th√¥ng tin b·ªï sung."""
    
    with st.sidebar:
        st.markdown("## üêæ Dog vs Cat Classifier")
        st.markdown("---")
        
        st.markdown("### üìñ V·ªÅ project")
        st.markdown("""
        ƒê√¢y l√† ·ª©ng d·ª•ng demo model **ConvMixer** ƒë∆∞·ª£c hu·∫•n luy·ªán 
        tr√™n dataset Dog vs Cat.
        
        **Paper g·ªëc:** *"Patches Are All You Need?"*
        """)
        
        st.markdown("---")
        
        st.markdown("### üõ†Ô∏è Th√¥ng tin k·ªπ thu·∫≠t")
        st.markdown(f"""
        - **Model:** ConvMixer-768/32
        - **Input size:** 224x224
        - **Classes:** Cat, Dog
        - **Framework:** PyTorch + timm
        """)
        
        st.markdown("---")
        
        st.markdown("### üîó Links")
        st.markdown("""
        - [ConvMixer Paper](https://arxiv.org/abs/2201.09792)
        - [timm Library](https://github.com/huggingface/pytorch-image-models)
        """)
        
        st.markdown("---")
        
        # Device info
        device = "CUDA üöÄ" if torch.cuda.is_available() else "CPU"
        st.info(f"**Device:** {device}")


# ============================================================================
# MAIN APP
# ============================================================================
def main():
    """H√†m ch√≠nh ch·∫°y ·ª©ng d·ª•ng."""
    
    # Render sidebar
    render_sidebar()
    
    # Header
    st.markdown('<h1 class="main-header">üê± Dog vs Cat Classifier üê∂</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Powered by ConvMixer - "Patches Are All You Need?"</p>', unsafe_allow_html=True)
    
    # Tabs
    tab1, tab2 = st.tabs(["üéÆ Demo", "üìä Report"])
    
    with tab1:
        render_demo_tab()
    
    with tab2:
        render_report_tab()
    
    # Footer
    st.markdown("---")
    st.markdown(
        "<p style='text-align: center; color: #888;'>Made with ‚ù§Ô∏è using Streamlit | Machine Learning Project</p>",
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
